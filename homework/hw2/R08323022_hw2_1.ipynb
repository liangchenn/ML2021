{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "R08323022_hw2-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ3xD9uEDXV-"
      },
      "source": [
        "# ML 2021 Homework 2-1\n",
        "\n",
        "- Author : Liang-Cheng Chen 陳亮丞\n",
        "- Mail : r08323022@ntu.edu.tw\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf6XqLsK6M1Q"
      },
      "source": [
        "## Synopsis\n",
        "\n",
        "### Train\n",
        "\n",
        "I test three DNN model setups, also I test different ways to split train/validate sets.\n",
        "\n",
        "I find models with more hidden layers and dropout perform better. \n",
        "\n",
        "Additionally, using randomly split train/validate data does not give us better results. A guess here is that the order of data may be related to the speakers. Therefore using randomly split sets may let validation data be too similar with the training data.\n",
        "I also find adding batchnorm to each layer does not give me better prediction.\n",
        "\n",
        "In the final version, I let three models decide the predicted value with majority vote. (Yet this did not yield better result than model 3.)\n",
        "\n",
        "### Post-Processing\n",
        "\n",
        "I find the prediction values appear to last for several frames. (each row is a frame, a phoneme consists of multiple frame).\n",
        "Hence, I use `post_process` function to correct the prediction yielded by the model.\n",
        "\n",
        "\n",
        "### Ref\n",
        "\n",
        "I follow the same way to build the `TIMITDataset`, and the same way to calculate batch loss as the code provided by the course TA, the [link] is [here](https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/HW02/HW02-1.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWRmsO-qBWry"
      },
      "source": [
        "## Model and Tools\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsGJFw_XFsjS"
      },
      "source": [
        "# Modules\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import csv\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gc"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yGU84PRD7cs"
      },
      "source": [
        "### Some Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DTCjLPRD7NO"
      },
      "source": [
        "def train_val_split(X, y, shuffle=False, ratio=0.2):\n",
        "    '''\n",
        "    train/validation split with val ratio provided and data shuffled.\n",
        "    '''\n",
        "\n",
        "    if shuffle:\n",
        "        idx = np.random.permutation(X.shape[0])\n",
        "        X, y = X[idx], y[idx]\n",
        "\n",
        "    percent = int(X.shape[0]*(1-ratio))\n",
        "\n",
        "    return X[:percent], y[:percent], X[percent:], y[percent:]\n",
        "\n",
        "\n",
        "#check device\n",
        "def get_device():\n",
        "  return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# fix random seed\n",
        "def same_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  \n",
        "    np.random.seed(seed)  \n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3le6YLI7D4AR"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sYw7PWB6GNB"
      },
      "source": [
        "class TIMITDataset(Dataset):\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.data = torch.from_numpy(X).float()\n",
        "        \n",
        "        if y is not None:\n",
        "            y = y.astype(int) \n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        if self.label is not None:\n",
        "            # Train and Val dataset\n",
        "            return self.data[index], self.label[index]\n",
        "        else:\n",
        "            # Test dataset\n",
        "            return self.data[index]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfprfIqcCYOq"
      },
      "source": [
        "### Model \n",
        "In the `TIMITClassifier` object I define three network setups and implement loss function with L2-regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HysENMme6FBN"
      },
      "source": [
        "class TIMITClassifier(nn.Module):\n",
        "    def __init__(self, mode=1):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.mode = mode\n",
        "        self.mpath = \"./model{}.pth\".format(mode)\n",
        "\n",
        "        # model architecture\n",
        "        self.net1 = nn.Sequential(\n",
        "            nn.Linear(429, 1024),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Dropout(p=0.2),\n",
        "\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Dropout(p=0.2),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Dropout(p=0.2),\n",
        "\n",
        "            nn.Linear(512, 128),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(128, 39)\n",
        "        )\n",
        "\n",
        "        self.net2 = nn.Sequential(\n",
        "            nn.Linear(429, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Dropout(p=0.2),\n",
        "\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Dropout(p=0.2),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Dropout(p=0.2),\n",
        "\n",
        "            nn.Linear(512, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(128, 39)\n",
        "        )\n",
        "\n",
        "        self.net3 = nn.Sequential(\n",
        "            nn.Linear(429, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2),\n",
        "\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2),\n",
        "\n",
        "            nn.Linear(512, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(128, 39)\n",
        "        )\n",
        "\n",
        "\n",
        "        # loss function\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    def cal_loss(self, pred, y, L2=False):\n",
        "        '''\n",
        "        Loss with L2-regularization.\n",
        "        '''\n",
        "        if L2:\n",
        "\n",
        "            l2_lambda = 0.0001\n",
        "            l2_reg = 0\n",
        "\n",
        "            for param in model.parameters():\n",
        "                l2_reg += torch.sum(param.pow(2))\n",
        "\n",
        "            loss = self.criterion(pred, y) + l2_lambda * l2_reg\n",
        "\n",
        "        else:\n",
        "            loss = self.criterion(pred, y)\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if self.mode == 1:\n",
        "            return self.net1(x)\n",
        "        elif self.mode == 2:\n",
        "            return self.net2(x)\n",
        "        else:\n",
        "            return self.net3(x)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15yNIFagDyXY"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjZiO_MkEIVL"
      },
      "source": [
        "def train(model, train_loader, val_loader, num_epoch, lr, device, L2=False):\n",
        "\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(num_epoch):\n",
        "\n",
        "        train_acc = 0.0\n",
        "        val_acc   = 0.0\n",
        "        train_loss = 0.0\n",
        "        val_loss   = 0.0\n",
        "        \n",
        "\n",
        "        # training part\n",
        "        model.train()\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            \n",
        "            optim.zero_grad()                       # remove previous grad\n",
        "            outputs = model(x)                      # prediction prob. in (1, 39) shape\n",
        "            loss = model.cal_loss(outputs, y, L2)       # calculate loss\n",
        "            loss.backward()                         # back propagation\n",
        "            optim.step()                            # update params\n",
        "\n",
        "            _, pred = torch.max(outputs, 1)         # get category with max prob., only need the index\n",
        "\n",
        "            # update total loss\n",
        "            train_acc += (pred.cpu() == y.cpu()).sum().item()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        \n",
        "        # validation\n",
        "        model.eval()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for x, y in val_loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                outputs = model(x)\n",
        "                loss = model.cal_loss(outputs, y, L2)\n",
        "                _, pred = torch.max(outputs, dim=1)\n",
        "\n",
        "                val_acc += (pred.cpu() == y.cpu()).sum().item()\n",
        "                val_loss += loss.item()\n",
        "\n",
        "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
        "                    epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
        "            ))\n",
        "\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                torch.save(model.state_dict(), model.mpath)\n",
        "                print(\"saving model with acc: {:.3f}\".format(best_acc/len(val_set)))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_x4j7XdEQKz"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx64dJv9ERWQ"
      },
      "source": [
        "def predict(model, test_loader, device):\n",
        "\n",
        "    predicts = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x in test_loader:\n",
        "            x = x.to(device)\n",
        "            outputs = model(x)\n",
        "            _, pred = torch.max(outputs, 1)\n",
        "\n",
        "            for y in pred.cpu().numpy():\n",
        "                predicts.append(y)\n",
        "\n",
        "    return predicts\n",
        "\n",
        "\n",
        "def save_pred(pred:list, filepath:str):\n",
        "\n",
        "    with open(filepath, 'w') as f:\n",
        "        f.write('Id,Class\\n')\n",
        "        for i, y in enumerate(pred):\n",
        "            f.write('{},{}\\n'.format(i, y))\n",
        "\n",
        "    print('Finish saving prediction at {}'.format(filepath))\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enNV_WK3EYgG"
      },
      "source": [
        "### Post-Processing\n",
        "The `post_process` function takes prediction list as input. It loops over each row, check whether the value is the same within `n`-window, then return a new prediction list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUHPSCpMEY2n"
      },
      "source": [
        "def post_process(pred:list, window=2):\n",
        "\n",
        "    posts = []\n",
        "    new_pred = pred[:]\n",
        "\n",
        "    for i, p in enumerate(new_pred):\n",
        "    \n",
        "        if i <= window or i + window >= (len(new_pred) - 1):\n",
        "            continue\n",
        "        \n",
        "        \n",
        "        tmp = new_pred[i-window:i] + new_pred[i+1:i+(window+1)]\n",
        "\n",
        "        if len(set(tmp)) == 1 and p not in set(tmp):\n",
        "            posts.append({\"i\" : i, \"value\" : p})\n",
        "            new_pred[i] = tmp[0]\n",
        "\n",
        "\n",
        "    return new_pred"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj97pCAkGdJQ"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNfcSZjYGb99",
        "outputId": "b7b717ca-c00e-4049-cd85-5e843c0a233f"
      },
      "source": [
        "!gdown --id '1HmENtrgZO1C13YM1mRenwDUvLCKX0ehu' --output data.zip\n",
        "!unzip data.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HmENtrgZO1C13YM1mRenwDUvLCKX0ehu\n",
            "To: /content/data.zip\n",
            "372MB [00:06, 61.6MB/s]\n",
            "Archive:  data.zip\n",
            "   creating: timit_11/\n",
            "  inflating: timit_11/train_11.npy   \n",
            "  inflating: timit_11/test_11.npy    \n",
            "  inflating: timit_11/train_label_11.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD7iZ_YQGfIk"
      },
      "source": [
        "pre = 'timit_11/'\n",
        "label_raw = np.load(pre + 'train_label_11.npy')\n",
        "train_raw = np.load(pre +'train_11.npy')\n",
        "test_raw  = np.load(pre + 'test_11.npy')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3LQ0wAqGlyS"
      },
      "source": [
        "train_x, train_y, val_x, val_y = train_val_split(train_raw, label_raw, shuffle=False, ratio=0.2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-lKMJpTGqPy"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "train_set = TIMITDataset(train_x, train_y)\n",
        "val_set   = TIMITDataset(val_x, val_y)\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8FB-XS1GthM",
        "outputId": "e5831928-a6ef-41a9-b075-4c9da6c191dc"
      },
      "source": [
        "del train_raw, label_raw, train_x, train_y, val_x, val_y\n",
        "gc.collect()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iy1RwnAFaMo"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKM71DUqFbFI"
      },
      "source": [
        "# set up hyper params\n",
        "\n",
        "NUM_EPOCH = 20\n",
        "LR = 0.0001\n",
        "device = get_device()\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BcawvAuHaRv",
        "outputId": "42ee2907-0617-434d-ea1a-cb571b0f9e0c"
      },
      "source": [
        "# initialize model and train\n",
        "same_seeds(3)\n",
        "model = TIMITClassifier(mode=3).to(device)\n",
        "\n",
        "_ = train(model, train_loader, val_loader, NUM_EPOCH, LR, device)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[001/020] Train Acc: 0.580011 Loss: 1.494414 | Val Acc: 0.685276 loss: 1.014293\n",
            "saving model with acc: 0.685\n",
            "[002/020] Train Acc: 0.659675 Loss: 1.085380 | Val Acc: 0.707525 loss: 0.912328\n",
            "saving model with acc: 0.708\n",
            "[003/020] Train Acc: 0.681216 Loss: 0.999055 | Val Acc: 0.716302 loss: 0.872746\n",
            "saving model with acc: 0.716\n",
            "[004/020] Train Acc: 0.695114 Loss: 0.945637 | Val Acc: 0.724876 loss: 0.837717\n",
            "saving model with acc: 0.725\n",
            "[005/020] Train Acc: 0.705356 Loss: 0.906166 | Val Acc: 0.730933 loss: 0.816636\n",
            "saving model with acc: 0.731\n",
            "[006/020] Train Acc: 0.714728 Loss: 0.873916 | Val Acc: 0.734827 loss: 0.801216\n",
            "saving model with acc: 0.735\n",
            "[007/020] Train Acc: 0.721775 Loss: 0.847594 | Val Acc: 0.735787 loss: 0.798758\n",
            "saving model with acc: 0.736\n",
            "[008/020] Train Acc: 0.727827 Loss: 0.824674 | Val Acc: 0.738824 loss: 0.785220\n",
            "saving model with acc: 0.739\n",
            "[009/020] Train Acc: 0.733522 Loss: 0.804724 | Val Acc: 0.741438 loss: 0.780324\n",
            "saving model with acc: 0.741\n",
            "[010/020] Train Acc: 0.738233 Loss: 0.787325 | Val Acc: 0.744576 loss: 0.770262\n",
            "saving model with acc: 0.745\n",
            "[011/020] Train Acc: 0.742721 Loss: 0.770755 | Val Acc: 0.743507 loss: 0.773180\n",
            "[012/020] Train Acc: 0.746962 Loss: 0.756069 | Val Acc: 0.744901 loss: 0.771727\n",
            "saving model with acc: 0.745\n",
            "[013/020] Train Acc: 0.751161 Loss: 0.742088 | Val Acc: 0.746531 loss: 0.766668\n",
            "saving model with acc: 0.747\n",
            "[014/020] Train Acc: 0.753479 Loss: 0.731704 | Val Acc: 0.746129 loss: 0.767117\n",
            "[015/020] Train Acc: 0.756824 Loss: 0.720522 | Val Acc: 0.746434 loss: 0.763106\n",
            "[016/020] Train Acc: 0.760826 Loss: 0.709593 | Val Acc: 0.746109 loss: 0.768412\n",
            "[017/020] Train Acc: 0.763052 Loss: 0.700121 | Val Acc: 0.746357 loss: 0.769842\n",
            "[018/020] Train Acc: 0.766184 Loss: 0.689937 | Val Acc: 0.746328 loss: 0.769232\n",
            "[019/020] Train Acc: 0.768752 Loss: 0.681592 | Val Acc: 0.747682 loss: 0.768145\n",
            "saving model with acc: 0.748\n",
            "[020/020] Train Acc: 0.770481 Loss: 0.675020 | Val Acc: 0.748133 loss: 0.764750\n",
            "saving model with acc: 0.748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEe-FdlmJG_g"
      },
      "source": [
        "# prepare test dataloader\n",
        "test_set = TIMITDataset(test_raw, None)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFswBhOIIOfR",
        "outputId": "76b1bd1e-6529-4c7e-8362-016dfaface87"
      },
      "source": [
        "# reload model\n",
        "model = TIMITClassifier(mode=3).to(device)\n",
        "model.load_state_dict(torch.load(model.mpath))\n",
        "\n",
        "# predict\n",
        "pred = predict(model, test_loader, device)\n",
        "save_pred(pred, 'old_pred_3.csv')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finish saving prediction at old_pred_3.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjCTeL5tISyY"
      },
      "source": [
        "Then we repeat above steps for different models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1rqQBsjIYON"
      },
      "source": [
        "# initialize model and train\n",
        "same_seeds(2)\n",
        "model = TIMITClassifier(mode=2).to(device)\n",
        "\n",
        "_ = train(model, train_loader, val_loader, NUM_EPOCH, LR, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoFEIP2TJAGg"
      },
      "source": [
        "# reload model\n",
        "model = TIMITClassifier(mode=2).to(device)\n",
        "model.load_state_dict(torch.load(model.mpath))\n",
        "\n",
        "# predict\n",
        "pred = predict(model, test_loader, device)\n",
        "save_pred(pred, 'old_pred_2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSywyvJkJLkM"
      },
      "source": [
        "# initialize model and train\n",
        "same_seeds(1)\n",
        "model = TIMITClassifier(mode=1).to(device)\n",
        "\n",
        "_ = train(model, train_loader, val_loader, NUM_EPOCH, LR, device)\n",
        "\n",
        "# reload model\n",
        "model = TIMITClassifier(mode=1).to(device)\n",
        "model.load_state_dict(torch.load(model.mpath))\n",
        "\n",
        "# predict\n",
        "pred = predict(model, test_loader, device)\n",
        "save_pred(pred, 'old_pred_1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81qMZf8KJP4V"
      },
      "source": [
        "## Post-Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p7TzxLOJVVz"
      },
      "source": [
        "import pandas as pd\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDM0O4vxJZoG"
      },
      "source": [
        "Load prediction lists for models, decide the predictions with majority vote. (If all three models predict differently, then use either one.) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ny1VNmAJXed"
      },
      "source": [
        "pred3 = pd.read_csv('./old_pred_3.csv').Class.to_list()\n",
        "pred2 = pd.read_csv('./old_pred_2.csv').Class.to_list()\n",
        "pred1 = pd.read_csv('./old_pred_1.csv').Class.to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxrvrUm6Je-r"
      },
      "source": [
        "res = []\n",
        "for a, b, c in zip(pred3, pred2, pred1):\n",
        "    res.append(Counter([a, b, c]).most_common()[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPNvn92SJ7FO"
      },
      "source": [
        "new_res = post_process(res, window=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkFsbSPmJ_Ca"
      },
      "source": [
        "save_pred(res, 'pred.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FRANx_ANtSW"
      },
      "source": [
        "## Reference\n",
        "\n",
        "- TA's Hw2 sample code [link](https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/HW02/HW02-1.ipynb#scrollTo=emUd7uS7crTz)"
      ]
    }
  ]
}